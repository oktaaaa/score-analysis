{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea03d87a",
   "metadata": {},
   "source": [
    "# Score Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc245ea",
   "metadata": {},
   "source": [
    "I made a score analysis of the students' reading examination. The reading questions consist of inference, direct and indirect, main ideas, and vocabulary. \n",
    "To do the test, I used Google form. As for the result, I downloaded the file in .csv. Here is it looks like (The students' name are covered):\n",
    "<img src = 'reading1.png' width = '1500' height= '350'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebfa7ae",
   "metadata": {},
   "source": [
    "1. Open the .csv file\n",
    "2. Dropped Timestamp and Score because the columns are not needed. Questions need to be checked one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae7d49d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "read = pd.read_csv('reading.csv')\n",
    "read = read.drop(['Timestamp','Score'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e2a3de",
   "metadata": {},
   "source": [
    "This is what the data looks like after the two columns dropped.\n",
    "<img src = 'reading2.png' width = '700' height= '350'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca7d067",
   "metadata": {},
   "source": [
    "3. Other than Name: column, the column names consist of NUMBER and QUESTION of the test. \n",
    "Since I only need numbers, I change all column names into numbers, including Name: column.\n",
    "So, the Name: column is changed into '0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58498822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n",
       "       '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24',\n",
       "       '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36',\n",
       "       '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48',\n",
       "       '49', '50'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "read.columns = [str(i) for i in range(len(read.columns))]\n",
    "read.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d887f927",
   "metadata": {},
   "source": [
    "4. Every column consists of answers with LETTERS and the description of the annswer. \n",
    "    For further use, what I need are the letters.\n",
    "    To achieve that:\n",
    "        a. Group the columns for questions.\n",
    "        b. Extract the letter only.\n",
    "        c. Merge the 0 column (name) with columns \n",
    "        for questions that have been extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4e5cda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "  \n",
    "col_num = read.iloc[:,1:51]\n",
    "read_1 = col_num.apply(lambda c: c.str.extract('\\((.*?)\\)', expand=False))\n",
    "#read.col_num= read_1\n",
    "read_clean = pd.concat([read['0'], read_1], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3997951",
   "metadata": {},
   "source": [
    "<img src = 'extract.png' width = '1500' height= '350'>\n",
    "\n",
    "5. Then, I group the numbers into some categoeries as well as the       \n",
    "    correct answer to those numbers.\n",
    "        \n",
    "        For instance, I need to find out how many correct numbers student get for inference \n",
    "        questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b25d36b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group the lesson details\n",
    "infer = read_clean[['2', '4', '19', '25', '26', '33', '36', '44']]\n",
    "infer_ans = ['D', 'A', 'D', 'B', 'D', 'C', 'D', 'A']\n",
    "\n",
    "direct_qs = read_clean[['6', '8', '10', '15', '17', '21', '24', '34', '37', '39', '41', '42', '47']]\n",
    "direct_ans = ['C', 'B', 'D', 'C', 'A', 'A', 'A', 'B', 'C', 'D', 'B', 'B', 'C']\n",
    "main_ideas = read_clean[['1', '11', '13', '20', '30', '40', '50']]\n",
    "main_ideas_ans = ['C','B', 'D', 'B', 'D', 'D', 'C']\n",
    "\n",
    "vocab = read_clean[['5', '7', '9', '12', '14', '16', '18', '22', '23', '27', '28', '31', '32', '35','38', '43', '45','46', '48']]\n",
    "vocab_ans = ['B', 'D', 'A', 'B', 'A', 'C', 'B', 'D', 'A', 'A', 'D', 'B', 'A', 'A', 'B', 'C', 'D', 'B', 'C']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fa26bf",
   "metadata": {},
   "source": [
    "6. Compare students' answers with correct answers.\n",
    "7. For every correct question students get, it will be summed and put into new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b341faf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_correct = infer == infer_ans\n",
    "read_clean['infer_total'] = infer_correct.sum(axis = 1)\n",
    "\n",
    "direct_qs_correct = direct_qs == direct_ans\n",
    "read_clean['direct_qs'] = direct_qs_correct.sum(axis = 1)\n",
    "\n",
    "main_ideas_correct = main_ideas == main_ideas_ans\n",
    "read_clean['main_ideas'] = main_ideas_correct.sum(axis = 1)\n",
    "\n",
    "vocab_correct = vocab == vocab_ans\n",
    "read_clean['vocabs'] = vocab_correct.sum(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b4042f",
   "metadata": {},
   "source": [
    "<img src = 'sums.png' width = '400' height= '400'>\n",
    "\n",
    "8. I want to get the description from correct answers student get for \n",
    "    every category. \n",
    "\n",
    "    For example, Student 1 gets all correct answers for Inference questions. It means his/her \n",
    "    ability to answer inference question was excellent.\n",
    "    \n",
    "9. Because every category of question has differenct amount of numbers, \n",
    "    so I separate the functions to get the desciption. \n",
    "\n",
    "10. The description for every category is randomised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59b7a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "all_true_des = [' was excellent', ' was very good', 'scored well'] \n",
    "half_true = [' was decent', ' was good', ' was average', 'was so-so']\n",
    "not_really = [' needed improvement', ' needed a lof of practice', ' needed practice more']\n",
    "\n",
    "#infer_total: 6-8(all_true), 3-5 (half_true), 0-2(not_really)\n",
    "def set_desc(row):\n",
    "    if row[\"infer_total\"] < 3:\n",
    "        return random.choice(not_really)\n",
    "    elif row[\"infer_total\"] < 6:\n",
    "        return random.choice(half_true)\n",
    "    elif row[\"infer_total\"] <= 8:\n",
    "        return random.choice(all_true_des)\n",
    "\n",
    "#direct: 13\n",
    "def direct(row):\n",
    "    if row['direct_qs'] <= 4:\n",
    "        return random.choice(not_really)\n",
    "    elif row['direct_qs'] >= 5 and row['direct_qs'] <= 9:\n",
    "        return random.choice(half_true )\n",
    "    elif row['direct_qs'] <= 13:\n",
    "        return random.choice(all_true_des)\n",
    "\n",
    "def main(row): #7 \n",
    "    if row[\"main_ideas\"] < 2:\n",
    "        return random.choice(not_really)\n",
    "    elif row[\"main_ideas\"] <= 7:\n",
    "        return random.choice(all_true_des)\n",
    "    elif row[\"main_ideas\"] < 5:\n",
    "        return random.choice(half_true)\n",
    "\n",
    "# vocab : 14-19(all_true), 7-13 (half_true), 0-6(not_really)\n",
    "\n",
    "def vocab(row):\n",
    "    if row['vocabs'] <= 6:\n",
    "        return random.choice(not_really)\n",
    "    elif row['vocabs'] >= 7 and row['vocabs'] <= 13:\n",
    "        return random.choice(half_true )\n",
    "    elif row['vocabs'] <= 19:\n",
    "        return random.choice(all_true_des)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0a5974",
   "metadata": {},
   "source": [
    "11. Put all the descriptions for every categories in new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b810d8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_clean = read_clean.assign(infer_desc=read_clean.apply(set_desc, axis=1))\n",
    "read_clean = read_clean.assign(direct_qs_desc=read_clean.apply(direct, axis=1))\n",
    "read_clean = read_clean.assign(main_desc=read_clean.apply(main, axis=1))\n",
    "read_clean = read_clean.assign(vocab_desc=read_clean.apply(vocab, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a4c3a3",
   "metadata": {},
   "source": [
    "<img src = 'description.png' width = '800' height= '400'>\n",
    "\n",
    "12. Then loop through the whole data to get the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f10941ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for (student, infer, direct, main, vocab) in zip(read_clean['0'], read_clean['infer_desc'], read_clean['direct_qs_desc'], read_clean['main_desc'],read_clean['vocab_desc'] ): \\n    print(f'When it comes to reading, {student}, the abilities to answer inference questions {infer}, direct and indirect questions {direct}, main idea questions {main}, and vocabulary questions {vocab}')\\n    \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_clean['reading'] = random.choices(['When it comes to reading, ', 'As for reading, ', 'For reading comprehension, '], weights=[1, 1,1], k=len(read_clean))\n",
    "\n",
    "'''for (student, infer, direct, main, vocab) in zip(read_clean['0'], read_clean['infer_desc'], read_clean['direct_qs_desc'], read_clean['main_desc'],read_clean['vocab_desc'] ): \n",
    "    print(f'When it comes to reading, {student}, the abilities to answer inference questions {infer}, direct and indirect questions {direct}, main idea questions {main}, and vocabulary questions {vocab}')\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da15bbe8",
   "metadata": {},
   "source": [
    "<img src = 'analysis.png' width = '1000' height= '500'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
