{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea03d87a",
   "metadata": {},
   "source": [
    "# Score Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc245ea",
   "metadata": {},
   "source": [
    "I made a score analysis of the students' reading examination. The reading questions consist of inference, direct and indirect, main ideas, and vocabulary. \n",
    "To do the test, I used Google form. As for the result, I downloaded the file in .csv. Here is it looks like (The students' name are covered):\n",
    "<img src = 'reading1.png' width = '1500' height= '500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebfa7ae",
   "metadata": {},
   "source": [
    "1. I opened the .csv file\n",
    "2. I dropped Timestamp and Score because I did not need the two columns. I need the question to be checked one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7d49d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "read = pd.read_csv('reading.csv')\n",
    "read = read.drop(['Timestamp','Score'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e2a3de",
   "metadata": {},
   "source": [
    "This is what the data looks like after the two columns dropped.\n",
    "<img src = 'reading2.png' width = '1000' height= '1000'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58498822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read.rename(columns={x:y for x,y in zip(read.columns,range(0,len(read.columns)))})\n",
    "#change the whole columns name to numbers\n",
    "read.columns = [str(i) for i in range(len(read.columns))]\n",
    "read.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e5cda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "  \n",
    "col_num = read.iloc[:,1:51]\n",
    "read_1 = col_num.apply(lambda c: c.str.extract('\\((.*?)\\)', expand=False))\n",
    "#read.col_num= read_1\n",
    "read_clean = pd.concat([read['0'], read_1], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25d36b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group the lesson details\n",
    "infer = read_clean[['2', '4', '19', '25', '26', '33', '36', '44']]\n",
    "infer_ans = ['D', 'A', 'D', 'B', 'D', 'C', 'D', 'A']\n",
    "\n",
    "direct_qs = read_clean[['6', '8', '10', '15', '17', '21', '24', '34', '37', '39', '41', '42', '47']]\n",
    "direct_ans = ['C', 'B', 'D', 'C', 'A', 'A', 'A', 'B', 'C', 'D', 'B', 'B', 'C']\n",
    "main_ideas = read_clean[['1', '11', '13', '20', '30', '40', '50']]\n",
    "main_ideas_ans = ['C','B', 'D', 'B', 'D', 'D', 'C']\n",
    "\n",
    "vocab = read_clean[['5', '7', '9', '12', '14', '16', '18', '22', '23', '27', '28', '31', '32', '35','38', '43', '45','46', '48']]\n",
    "vocab_ans = ['B', 'D', 'A', 'B', 'A', 'C', 'B', 'D', 'A', 'A', 'D', 'B', 'A', 'A', 'B', 'C', 'D', 'B', 'C']\n",
    "\n",
    "''' check whether the answers are correct or not and sum the amount'''\n",
    "infer_correct = infer == infer_ans\n",
    "read_clean['infer_total'] = infer_correct.sum(axis = 1)\n",
    "\n",
    "direct_qs_correct = direct_qs == direct_ans\n",
    "read_clean['direct_qs'] = direct_qs_correct.sum(axis = 1)\n",
    "\n",
    "main_ideas_correct = main_ideas == main_ideas_ans\n",
    "read_clean['main_ideas'] = main_ideas_correct.sum(axis = 1)\n",
    "\n",
    "vocab_correct = vocab == vocab_ans\n",
    "read_clean['vocabs'] = vocab_correct.sum(axis = 1)\n",
    "\n",
    "\n",
    "all_true_des = [' was excellent', ' was very good', 'scored well'] \n",
    "half_true = [' was decent', ' was good', ' was average', 'was so-so']\n",
    "not_really = [' needed improvement', ' needed a lof of practice', ' needed practice more']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b7a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#infer_total: 6-8(all_true), 3-5 (half_true), 0-2(not_really)\n",
    "def set_desc(row):\n",
    "    if row[\"infer_total\"] < 3:\n",
    "        return random.choice(not_really)\n",
    "    elif row[\"infer_total\"] < 6:\n",
    "        return random.choice(half_true)\n",
    "    elif row[\"infer_total\"] <= 8:\n",
    "        return random.choice(all_true_des)\n",
    "\n",
    "#direct: 13\n",
    "def direct(row):\n",
    "    if row['direct_qs'] <= 4:\n",
    "        return random.choice(not_really)\n",
    "    elif row['direct_qs'] >= 5 and row['direct_qs'] <= 9:\n",
    "        return random.choice(half_true )\n",
    "    elif row['direct_qs'] <= 13:\n",
    "        return random.choice(all_true_des)\n",
    "\n",
    "def main(row): #7 \n",
    "    if row[\"main_ideas\"] < 2:\n",
    "        return random.choice(not_really)\n",
    "    elif row[\"main_ideas\"] <= 7:\n",
    "        return random.choice(all_true_des)\n",
    "    elif row[\"main_ideas\"] < 5:\n",
    "        return random.choice(half_true)\n",
    "\n",
    "# vocab : 14-19(all_true), 7-13 (half_true), 0-6(not_really)\n",
    "\n",
    "def vocab(row):\n",
    "    if row['vocabs'] <= 6:\n",
    "        return random.choice(not_really)\n",
    "    elif row['vocabs'] >= 7 and row['vocabs'] <= 13:\n",
    "        return random.choice(half_true )\n",
    "    elif row['vocabs'] <= 19:\n",
    "        return random.choice(all_true_des)\n",
    "\n",
    "read_clean = read_clean.assign(infer_desc=read_clean.apply(set_desc, axis=1))\n",
    "read_clean = read_clean.assign(direct_qs_desc=read_clean.apply(direct, axis=1))\n",
    "read_clean = read_clean.assign(main_desc=read_clean.apply(main, axis=1))\n",
    "#check lagi main idea samo vocab\n",
    "read_clean = read_clean.assign(vocab_desc=read_clean.apply(vocab, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10941ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "for (student, infer, direct, main, vocab) in zip(read_clean['0'], read_clean['infer_desc'], read_clean['direct_qs_desc'], read_clean['main_desc'],read_clean['vocab_desc'] ): \n",
    "    print(f'When it comes to reading, {student}, the abilities to answer inference questions {infer}, direct and indirect questions {direct}, main idea questions {main}, and vocabulary questions {vocab}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d80beed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4578ec5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
